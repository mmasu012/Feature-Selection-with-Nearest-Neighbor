{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ee0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e3fed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORWARD_SELECTION, BACKWARD_ELIMINATION = 'forward_selection', 'backward_elimination'\n",
    "K_FOLD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4df63d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_path):\n",
    "\n",
    "    data = pd.read_csv(dataset_path, delim_whitespace=True, header = None)\n",
    "    instance_count, column_count = data.shape   \n",
    "    feature_count = column_count - 1\n",
    "    instances = data.values.tolist()\n",
    "    \n",
    "    return instances, instance_count, feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed580d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_euclidean_distance(instance, compare_instance, features):\n",
    "    \n",
    "    squares = 0\n",
    "    for feature in features:\n",
    "        \n",
    "        diff = instance[feature] - compare_instance[feature]\n",
    "        squares += diff ** 2\n",
    "    \n",
    "    return math.sqrt(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe9b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbor(dataset, feature_set, instance_count):\n",
    "    \n",
    "    correct_prediction = 0\n",
    "    for instance_idx in range(instance_count):\n",
    "        \n",
    "        instance = dataset[instance_idx]\n",
    "        target = instance[0]\n",
    "        features = feature_set \n",
    "        \n",
    "        nearest_neighbor_distance = math.inf\n",
    "        nearest_neighbor_predict = -1\n",
    "        \n",
    "        for compare_idx in range(instance_count):\n",
    "            \n",
    "            if compare_idx != instance_idx:\n",
    "                \n",
    "                compare_instance = dataset[compare_idx]\n",
    "                compare_target = compare_instance[0]\n",
    "                distance = find_euclidean_distance(instance,\n",
    "                                                  compare_instance,\n",
    "                                                  features)\n",
    "                \n",
    "                if distance < nearest_neighbor_distance:\n",
    "                        nearest_neighbor_distance = distance\n",
    "                        nearest_neighbor_predict = compare_target\n",
    "         \n",
    "        if nearest_neighbor_predict == target:\n",
    "            correct_prediction += 1\n",
    "        \n",
    "    return correct_prediction / instance_count\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50c0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_cross_validation(instances, instance_count, feature_set):\n",
    "    \n",
    "    \n",
    "    fold_size = instance_count//K_FOLD\n",
    "    accuracy_list = []\n",
    "    for k_fold_itr in range(1, K_FOLD):\n",
    "        \n",
    "        ## dataset\n",
    "        remove_start = (k_fold_itr - 1) * fold_size\n",
    "        remove_end = remove_start + fold_size\n",
    "        \n",
    "        dataset = instances[0:remove_start] + instances[remove_end: instance_count]\n",
    "        \n",
    "        accuracy = find_nearest_neighbor(dataset, feature_set, fold_size)\n",
    "        accuracy_list.append(accuracy)\n",
    "    \n",
    "    return sum(accuracy_list)/K_FOLD\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56d6ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_experiment(instances, instance_count, feature_count, search_type = FORWARD_SELECTION):\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(search_type.upper())\n",
    "    \n",
    "    all_feature_set = list(range(1, feature_count + 1))\n",
    "    accuracy = leave_one_out_cross_validation(\\\n",
    "                    instances, instance_count, all_feature_set)\n",
    "    print('Running nearest neighbor with all', feature_count, 'features, using leave-one-out evaluation',\n",
    "         'with accuracy', '{:0.1f}%'.format(accuracy * 100))\n",
    "    \n",
    "    if search_type == FORWARD_SELECTION:\n",
    "        current_feature_set = []\n",
    "    elif search_type == BACKWARD_ELIMINATION:\n",
    "        current_feature_set = all_feature_set\n",
    "    \n",
    "    print()\n",
    "    print('Beginning Search ')\n",
    "    best_accuracy_feature_set = all_feature_set\n",
    "    best_accuracy = accuracy\n",
    "    for level in range(1, feature_count):\n",
    "        \n",
    "        print('On the ', str(level), 'th level of the search tree')\n",
    "        level_wise_best_accuracy_feature_set = None\n",
    "        level_wise_best_accuracy_feature = None\n",
    "        level_wise_best_accuracy = 0\n",
    "        \n",
    "        for feature in range(1, feature_count + 1):\n",
    "            \n",
    "            if (feature not in current_feature_set and search_type == FORWARD_SELECTION) or \\\n",
    "                (feature in current_feature_set and search_type == BACKWARD_ELIMINATION):\n",
    "                \n",
    "                if search_type == FORWARD_SELECTION:\n",
    "                    feature_set = current_feature_set + [feature]\n",
    "                elif search_type == BACKWARD_ELIMINATION:\n",
    "                    feature_set = list(set(current_feature_set) - set([feature]))\n",
    "                    \n",
    "                accuracy = leave_one_out_cross_validation(\\\n",
    "                                instances, instance_count, \\\n",
    "                                feature_set)\n",
    "                \n",
    "                feature_set.sort()\n",
    "                feature_set_string = '{' + ','.join(str(f) for f in feature_set) + '}'\n",
    "                print('\\t Using features',  feature_set_string, 'accuracy is', '{:0.1f}%'.format(accuracy * 100) )\n",
    "                \n",
    "                if accuracy > level_wise_best_accuracy:\n",
    "                    level_wise_best_accuracy = accuracy\n",
    "                    level_wise_best_accuracy_feature = feature\n",
    "                    level_wise_best_accuracy_feature_set = feature_set\n",
    "                    \n",
    "        if search_type == FORWARD_SELECTION:\n",
    "            current_feature_set.append(level_wise_best_accuracy_feature)\n",
    "            add_remove_log = 'adding ' + 'feature ' + str(level_wise_best_accuracy_feature)\n",
    "        elif search_type == BACKWARD_ELIMINATION:\n",
    "            current_feature_set = list(set(current_feature_set) - set([level_wise_best_accuracy_feature]))\n",
    "            add_remove_log = 'removing ' + 'feature ' + str(level_wise_best_accuracy_feature)\n",
    "            \n",
    "        \n",
    "        level_wise_best_feature_set_string = '{' + ','.join(str(f) for f in level_wise_best_accuracy_feature_set) + '}'\n",
    "        print('Feature set ', level_wise_best_feature_set_string, \\\n",
    "              ' was best. accuracy is', '{:0.1f}%'.format(level_wise_best_accuracy*100), add_remove_log )\n",
    "        print()\n",
    "        \n",
    "        if level_wise_best_accuracy > best_accuracy:\n",
    "            best_accuracy = level_wise_best_accuracy\n",
    "            best_accuracy_feature_set = level_wise_best_accuracy_feature_set\n",
    "    \n",
    "    best_accuracy_feature_set_string = '{' + ','.join(str(f) for f in best_accuracy_feature_set) + '}'\n",
    "    print('Finished search !!', 'The best feature subset is', best_accuracy_feature_set_string, \\\n",
    "             'which has an accuracy of', '{:0.1f}%'.format(best_accuracy*100) )\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b6be4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def start_experiment(instances, instance_count, feature_count, search_type = FORWARD_SELECTION):\n",
    "    \n",
    "#     print(search_type)\n",
    "    \n",
    "#     feature_set = list(range(1, feature_count + 1))\n",
    "#     accuracy = leave_one_out_cross_validation(\\\n",
    "#                     instances, instance_count, feature_set)\n",
    "#     print('Running nearest neighbor with all', feature_count, 'features, using leave-one-out evaluation',\n",
    "#          'with accuracy', '{:0.1f}%'.format(accuracy * 100))\n",
    "    \n",
    "#     current_feature_set = []\n",
    "    \n",
    "#     print()\n",
    "#     print('Beginning Search ')\n",
    "#     best_accuracy_feature_set = feature_set\n",
    "#     best_accuracy = accuracy\n",
    "#     for level in range(1, feature_count - 1):\n",
    "        \n",
    "#         print('On the ', str(level), 'th level of the search tree')\n",
    "#         level_wise_best_accuracy_feature_set = None\n",
    "#         level_wise_best_accuracy_feature = None\n",
    "#         level_wise_best_accuracy = 0\n",
    "        \n",
    "#         for feature in range(1, feature_count - 1):\n",
    "            \n",
    "#             if feature not in current_feature_set:\n",
    "                \n",
    "#                 feature_set = current_feature_set + [feature]\n",
    "#                 accuracy = leave_one_out_cross_validation(\\\n",
    "#                                 instances, instance_count, \\\n",
    "#                                 feature_set)\n",
    "                \n",
    "#                 feature_set.sort()\n",
    "                \n",
    "#                 feature_set_string = ','.join(str(f) for f in feature_set)\n",
    "#                 print('\\t Using features',  feature_set_string, 'accuracy is', '{:0.1f}%'.format(accuracy * 100) )\n",
    "                \n",
    "#                 if accuracy > level_wise_best_accuracy:\n",
    "#                     level_wise_best_accuracy = accuracy\n",
    "#                     level_wise_best_accuracy_feature = feature\n",
    "#                     level_wise_best_accuracy_feature_set = feature_set\n",
    "                    \n",
    "                    \n",
    "#         current_feature_set.append(level_wise_best_accuracy_feature)\n",
    "#         level_wise_best_feature_set_string = ','.join(str(f) for f in level_wise_best_accuracy_feature_set)\n",
    "#         print('Feature set ', level_wise_best_feature_set_string, \\\n",
    "#               ' was best. accuracy is', '{:0.1f}%'.format(level_wise_best_accuracy*100) )\n",
    "#         print()\n",
    "        \n",
    "#         if level_wise_best_accuracy > best_accuracy:\n",
    "#             best_accuracy = level_wise_best_accuracy\n",
    "#             best_accuracy_feature_set = level_wise_best_accuracy_feature_set\n",
    "    \n",
    "#     best_accuracy_feature_set_string = ','.join(str(f) for f in best_accuracy_feature_set)\n",
    "#     print('Finished search !!', 'The best feature subset is', best_accuracy_feature_set_string, \\\n",
    "#              'which has an accuracy of', '{:0.1f}%'.format(best_accuracy*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4dd1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 11 to run Forward Selection with small dataset\n",
      "Press 12 to run Forward Selection with large dataset\n",
      "Press 21 to run Backward Elimination with small dataset\n",
      "Press 22 to run Backward Elimination with large dataset\n",
      "Press any other key to exit\n",
      "11\n",
      "Forward Selection selected with small dataset\n",
      "\n",
      "\n",
      "FORWARD_SELECTION\n",
      "Running nearest neighbor with all 10 features, using leave-one-out evaluation with accuracy 65.3%\n",
      "\n",
      "Beginning Search \n",
      "On the  1 th level of the search tree\n",
      "\t Using features {1} accuracy is 71.3%\n",
      "\t Using features {2} accuracy is 70.3%\n",
      "\t Using features {3} accuracy is 71.7%\n",
      "\t Using features {4} accuracy is 68.0%\n",
      "\t Using features {5} accuracy is 65.0%\n",
      "\t Using features {6} accuracy is 65.0%\n",
      "\t Using features {7} accuracy is 65.0%\n",
      "\t Using features {8} accuracy is 75.0%\n",
      "\t Using features {9} accuracy is 68.3%\n",
      "\t Using features {10} accuracy is 73.3%\n",
      "Feature set  {8}  was best. accuracy is 75.0% adding feature 8\n",
      "\n",
      "On the  2 th level of the search tree\n",
      "\t Using features {1,8} accuracy is 75.0%\n",
      "\t Using features {2,8} accuracy is 80.7%\n",
      "\t Using features {3,8} accuracy is 78.7%\n",
      "\t Using features {4,8} accuracy is 76.7%\n",
      "\t Using features {5,8} accuracy is 73.3%\n",
      "\t Using features {6,8} accuracy is 77.3%\n",
      "\t Using features {7,8} accuracy is 86.0%\n",
      "\t Using features {8,9} accuracy is 73.7%\n",
      "\t Using features {8,10} accuracy is 74.7%\n",
      "Feature set  {7,8}  was best. accuracy is 86.0% adding feature 7\n",
      "\n",
      "On the  3 th level of the search tree\n",
      "\t Using features {1,7,8} accuracy is 68.0%\n",
      "\t Using features {2,7,8} accuracy is 72.0%\n",
      "\t Using features {3,7,8} accuracy is 70.0%\n",
      "\t Using features {4,7,8} accuracy is 76.7%\n",
      "\t Using features {5,7,8} accuracy is 77.7%\n",
      "\t Using features {6,7,8} accuracy is 79.3%\n",
      "\t Using features {7,8,9} accuracy is 75.0%\n",
      "\t Using features {7,8,10} accuracy is 66.7%\n",
      "Feature set  {6,7,8}  was best. accuracy is 79.3% adding feature 6\n",
      "\n",
      "On the  4 th level of the search tree\n",
      "\t Using features {1,6,7,8} accuracy is 69.3%\n",
      "\t Using features {2,6,7,8} accuracy is 73.3%\n",
      "\t Using features {3,6,7,8} accuracy is 72.0%\n",
      "\t Using features {4,6,7,8} accuracy is 81.7%\n",
      "\t Using features {5,6,7,8} accuracy is 70.7%\n",
      "\t Using features {6,7,8,9} accuracy is 72.0%\n",
      "\t Using features {6,7,8,10} accuracy is 79.3%\n",
      "Feature set  {4,6,7,8}  was best. accuracy is 81.7% adding feature 4\n",
      "\n",
      "On the  5 th level of the search tree\n",
      "\t Using features {1,4,6,7,8} accuracy is 61.0%\n",
      "\t Using features {2,4,6,7,8} accuracy is 70.3%\n",
      "\t Using features {3,4,6,7,8} accuracy is 68.7%\n",
      "\t Using features {4,5,6,7,8} accuracy is 73.0%\n",
      "\t Using features {4,6,7,8,9} accuracy is 69.3%\n",
      "\t Using features {4,6,7,8,10} accuracy is 73.0%\n",
      "Feature set  {4,5,6,7,8}  was best. accuracy is 73.0% adding feature 5\n",
      "\n",
      "On the  6 th level of the search tree\n",
      "\t Using features {1,4,5,6,7,8} accuracy is 61.0%\n",
      "\t Using features {2,4,5,6,7,8} accuracy is 65.0%\n",
      "\t Using features {3,4,5,6,7,8} accuracy is 74.3%\n",
      "\t Using features {4,5,6,7,8,9} accuracy is 67.7%\n",
      "\t Using features {4,5,6,7,8,10} accuracy is 65.3%\n",
      "Feature set  {3,4,5,6,7,8}  was best. accuracy is 74.3% adding feature 3\n",
      "\n",
      "On the  7 th level of the search tree\n",
      "\t Using features {1,3,4,5,6,7,8} accuracy is 58.3%\n",
      "\t Using features {2,3,4,5,6,7,8} accuracy is 71.0%\n",
      "\t Using features {3,4,5,6,7,8,9} accuracy is 68.0%\n",
      "\t Using features {3,4,5,6,7,8,10} accuracy is 60.0%\n",
      "Feature set  {2,3,4,5,6,7,8}  was best. accuracy is 71.0% adding feature 2\n",
      "\n",
      "On the  8 th level of the search tree\n",
      "\t Using features {1,2,3,4,5,6,7,8} accuracy is 60.3%\n",
      "\t Using features {2,3,4,5,6,7,8,9} accuracy is 63.0%\n",
      "\t Using features {2,3,4,5,6,7,8,10} accuracy is 60.3%\n",
      "Feature set  {2,3,4,5,6,7,8,9}  was best. accuracy is 63.0% adding feature 9\n",
      "\n",
      "On the  9 th level of the search tree\n",
      "\t Using features {1,2,3,4,5,6,7,8,9} accuracy is 55.0%\n",
      "\t Using features {2,3,4,5,6,7,8,9,10} accuracy is 65.0%\n",
      "Feature set  {2,3,4,5,6,7,8,9,10}  was best. accuracy is 65.0% adding feature 10\n",
      "\n",
      "Finished search !! The best feature subset is {7,8} which has an accuracy of 86.0%\n",
      "\n",
      "\n",
      "Press 11 to run Forward Selection with small dataset\n",
      "Press 12 to run Forward Selection with large dataset\n",
      "Press 21 to run Backward Elimination with small dataset\n",
      "Press 22 to run Backward Elimination with large dataset\n",
      "Press any other key to exit\n",
      "21\n",
      "Backward Elimination selected with small dataset\n",
      "\n",
      "\n",
      "BACKWARD_ELIMINATION\n",
      "Running nearest neighbor with all 10 features, using leave-one-out evaluation with accuracy 65.3%\n",
      "\n",
      "Beginning Search \n",
      "On the  1 th level of the search tree\n",
      "\t Using features {2,3,4,5,6,7,8,9,10} accuracy is 65.0%\n",
      "\t Using features {1,3,4,5,6,7,8,9,10} accuracy is 63.0%\n",
      "\t Using features {1,2,4,5,6,7,8,9,10} accuracy is 65.7%\n",
      "\t Using features {1,2,3,5,6,7,8,9,10} accuracy is 69.0%\n",
      "\t Using features {1,2,3,4,6,7,8,9,10} accuracy is 65.7%\n",
      "\t Using features {1,2,3,4,5,7,8,9,10} accuracy is 63.7%\n",
      "\t Using features {1,2,3,4,5,6,8,9,10} accuracy is 63.3%\n",
      "\t Using features {1,2,3,4,5,6,7,9,10} accuracy is 64.0%\n",
      "\t Using features {1,2,3,4,5,6,7,8,10} accuracy is 57.3%\n",
      "\t Using features {1,2,3,4,5,6,7,8,9} accuracy is 55.0%\n",
      "Feature set  {1,2,3,5,6,7,8,9,10}  was best. accuracy is 69.0% removing feature 4\n",
      "\n",
      "On the  2 th level of the search tree\n",
      "\t Using features {2,3,5,6,7,8,9,10} accuracy is 70.3%\n",
      "\t Using features {1,3,5,6,7,8,9,10} accuracy is 66.3%\n",
      "\t Using features {1,2,5,6,7,8,9,10} accuracy is 64.3%\n",
      "\t Using features {1,2,3,6,7,8,9,10} accuracy is 63.7%\n",
      "\t Using features {1,2,3,5,7,8,9,10} accuracy is 66.7%\n",
      "\t Using features {1,2,3,5,6,8,9,10} accuracy is 66.7%\n",
      "\t Using features {1,2,3,5,6,7,9,10} accuracy is 66.0%\n",
      "\t Using features {1,2,3,5,6,7,8,10} accuracy is 61.0%\n",
      "\t Using features {1,2,3,5,6,7,8,9} accuracy is 64.0%\n",
      "Feature set  {2,3,5,6,7,8,9,10}  was best. accuracy is 70.3% removing feature 1\n",
      "\n",
      "On the  3 th level of the search tree\n",
      "\t Using features {3,5,6,7,8,9,10} accuracy is 68.0%\n",
      "\t Using features {2,5,6,7,8,9,10} accuracy is 67.3%\n",
      "\t Using features {2,3,6,7,8,9,10} accuracy is 68.3%\n",
      "\t Using features {2,3,5,7,8,9,10} accuracy is 69.7%\n",
      "\t Using features {2,3,5,6,8,9,10} accuracy is 73.0%\n",
      "\t Using features {2,3,5,6,7,9,10} accuracy is 68.0%\n",
      "\t Using features {2,3,5,6,7,8,10} accuracy is 63.7%\n",
      "\t Using features {2,3,5,6,7,8,9} accuracy is 65.7%\n",
      "Feature set  {2,3,5,6,8,9,10}  was best. accuracy is 73.0% removing feature 7\n",
      "\n",
      "On the  4 th level of the search tree\n",
      "\t Using features {3,5,6,8,9,10} accuracy is 74.0%\n",
      "\t Using features {2,5,6,8,9,10} accuracy is 65.3%\n",
      "\t Using features {2,3,6,8,9,10} accuracy is 65.0%\n",
      "\t Using features {2,3,5,8,9,10} accuracy is 73.3%\n",
      "\t Using features {2,3,5,6,9,10} accuracy is 73.3%\n",
      "\t Using features {2,3,5,6,8,10} accuracy is 63.0%\n",
      "\t Using features {2,3,5,6,8,9} accuracy is 65.3%\n",
      "Feature set  {3,5,6,8,9,10}  was best. accuracy is 74.0% removing feature 2\n",
      "\n",
      "On the  5 th level of the search tree\n",
      "\t Using features {5,6,8,9,10} accuracy is 68.3%\n",
      "\t Using features {3,6,8,9,10} accuracy is 65.3%\n",
      "\t Using features {3,5,8,9,10} accuracy is 70.3%\n",
      "\t Using features {3,5,6,9,10} accuracy is 76.7%\n",
      "\t Using features {3,5,6,8,10} accuracy is 66.3%\n",
      "\t Using features {3,5,6,8,9} accuracy is 72.0%\n",
      "Feature set  {3,5,6,9,10}  was best. accuracy is 76.7% removing feature 8\n",
      "\n",
      "On the  6 th level of the search tree\n",
      "\t Using features {5,6,9,10} accuracy is 74.0%\n",
      "\t Using features {3,6,9,10} accuracy is 65.7%\n",
      "\t Using features {3,5,9,10} accuracy is 73.0%\n",
      "\t Using features {3,5,6,10} accuracy is 71.3%\n",
      "\t Using features {3,5,6,9} accuracy is 69.3%\n",
      "Feature set  {5,6,9,10}  was best. accuracy is 74.0% removing feature 3\n",
      "\n",
      "On the  7 th level of the search tree\n",
      "\t Using features {6,9,10} accuracy is 68.3%\n",
      "\t Using features {5,9,10} accuracy is 68.3%\n",
      "\t Using features {5,6,10} accuracy is 65.0%\n",
      "\t Using features {5,6,9} accuracy is 68.7%\n",
      "Feature set  {5,6,9}  was best. accuracy is 68.7% removing feature 10\n",
      "\n",
      "On the  8 th level of the search tree\n",
      "\t Using features {6,9} accuracy is 71.0%\n",
      "\t Using features {5,9} accuracy is 74.3%\n",
      "\t Using features {5,6} accuracy is 65.3%\n",
      "Feature set  {5,9}  was best. accuracy is 74.3% removing feature 6\n",
      "\n",
      "On the  9 th level of the search tree\n",
      "\t Using features {9} accuracy is 68.3%\n",
      "\t Using features {5} accuracy is 65.0%\n",
      "Feature set  {9}  was best. accuracy is 68.3% removing feature 5\n",
      "\n",
      "Finished search !! The best feature subset is {3,5,6,9,10} which has an accuracy of 76.7%\n",
      "\n",
      "\n",
      "Press 11 to run Forward Selection with small dataset\n",
      "Press 12 to run Forward Selection with large dataset\n",
      "Press 21 to run Backward Elimination with small dataset\n",
      "Press 22 to run Backward Elimination with large dataset\n",
      "Press any other key to exit\n",
      "12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection selected with large dataset\n",
      "\n",
      "\n",
      "FORWARD_SELECTION\n",
      "Running nearest neighbor with all 40 features, using leave-one-out evaluation with accuracy 66.2%\n",
      "\n",
      "Beginning Search \n",
      "On the  1 th level of the search tree\n",
      "\t Using features {1} accuracy is 70.4%\n",
      "\t Using features {2} accuracy is 71.4%\n",
      "\t Using features {3} accuracy is 70.7%\n",
      "\t Using features {4} accuracy is 81.8%\n",
      "\t Using features {5} accuracy is 66.1%\n",
      "\t Using features {6} accuracy is 70.6%\n",
      "\t Using features {7} accuracy is 69.5%\n",
      "\t Using features {8} accuracy is 69.4%\n",
      "\t Using features {9} accuracy is 72.4%\n",
      "\t Using features {10} accuracy is 76.6%\n",
      "\t Using features {11} accuracy is 65.5%\n",
      "\t Using features {12} accuracy is 70.5%\n",
      "\t Using features {13} accuracy is 68.3%\n",
      "\t Using features {14} accuracy is 69.9%\n",
      "\t Using features {15} accuracy is 66.1%\n",
      "\t Using features {16} accuracy is 73.8%\n",
      "\t Using features {17} accuracy is 68.4%\n",
      "\t Using features {18} accuracy is 68.5%\n",
      "\t Using features {19} accuracy is 77.5%\n",
      "\t Using features {20} accuracy is 66.6%\n",
      "\t Using features {21} accuracy is 72.5%\n",
      "\t Using features {22} accuracy is 69.2%\n",
      "\t Using features {23} accuracy is 67.7%\n",
      "\t Using features {24} accuracy is 69.2%\n",
      "\t Using features {25} accuracy is 73.7%\n",
      "\t Using features {26} accuracy is 68.8%\n",
      "\t Using features {27} accuracy is 66.6%\n",
      "\t Using features {28} accuracy is 69.9%\n",
      "\t Using features {29} accuracy is 67.7%\n",
      "\t Using features {30} accuracy is 68.7%\n",
      "\t Using features {31} accuracy is 66.5%\n",
      "\t Using features {32} accuracy is 68.9%\n",
      "\t Using features {33} accuracy is 67.2%\n",
      "\t Using features {34} accuracy is 70.8%\n",
      "\t Using features {35} accuracy is 70.0%\n",
      "\t Using features {36} accuracy is 70.7%\n",
      "\t Using features {37} accuracy is 67.7%\n",
      "\t Using features {38} accuracy is 66.7%\n",
      "\t Using features {39} accuracy is 72.4%\n",
      "\t Using features {40} accuracy is 74.1%\n",
      "Feature set  {4}  was best. accuracy is 81.8% adding feature 4\n",
      "\n",
      "On the  2 th level of the search tree\n",
      "\t Using features {1,4} accuracy is 82.8%\n",
      "\t Using features {2,4} accuracy is 72.7%\n",
      "\t Using features {3,4} accuracy is 77.1%\n",
      "\t Using features {4,5} accuracy is 74.5%\n",
      "\t Using features {4,6} accuracy is 78.7%\n",
      "\t Using features {4,7} accuracy is 74.3%\n",
      "\t Using features {4,8} accuracy is 82.0%\n",
      "\t Using features {4,9} accuracy is 76.2%\n",
      "\t Using features {4,10} accuracy is 80.9%\n",
      "\t Using features {4,11} accuracy is 78.1%\n",
      "\t Using features {4,12} accuracy is 76.8%\n",
      "\t Using features {4,13} accuracy is 74.2%\n",
      "\t Using features {4,14} accuracy is 81.7%\n",
      "\t Using features {4,15} accuracy is 79.4%\n",
      "\t Using features {4,16} accuracy is 76.8%\n",
      "\t Using features {4,17} accuracy is 77.5%\n",
      "\t Using features {4,18} accuracy is 80.4%\n",
      "\t Using features {4,19} accuracy is 77.5%\n",
      "\t Using features {4,20} accuracy is 79.6%\n",
      "\t Using features {4,21} accuracy is 87.9%\n",
      "\t Using features {4,22} accuracy is 78.8%\n",
      "\t Using features {4,23} accuracy is 78.3%\n",
      "\t Using features {4,24} accuracy is 74.0%\n",
      "\t Using features {4,25} accuracy is 74.8%\n",
      "\t Using features {4,26} accuracy is 76.1%\n",
      "\t Using features {4,27} accuracy is 76.8%\n",
      "\t Using features {4,28} accuracy is 80.1%\n",
      "\t Using features {4,29} accuracy is 78.0%\n",
      "\t Using features {4,30} accuracy is 77.0%\n",
      "\t Using features {4,31} accuracy is 73.9%\n",
      "\t Using features {4,32} accuracy is 70.4%\n",
      "\t Using features {4,33} accuracy is 74.7%\n",
      "\t Using features {4,34} accuracy is 80.0%\n",
      "\t Using features {4,35} accuracy is 78.8%\n",
      "\t Using features {4,36} accuracy is 77.0%\n",
      "\t Using features {4,37} accuracy is 77.2%\n",
      "\t Using features {4,38} accuracy is 73.8%\n",
      "\t Using features {4,39} accuracy is 75.3%\n",
      "\t Using features {4,40} accuracy is 75.9%\n",
      "Feature set  {4,21}  was best. accuracy is 87.9% adding feature 21\n",
      "\n",
      "On the  3 th level of the search tree\n",
      "\t Using features {1,4,21} accuracy is 83.9%\n",
      "\t Using features {2,4,21} accuracy is 81.3%\n",
      "\t Using features {3,4,21} accuracy is 84.4%\n",
      "\t Using features {4,5,21} accuracy is 83.2%\n",
      "\t Using features {4,6,21} accuracy is 84.1%\n",
      "\t Using features {4,7,21} accuracy is 82.7%\n",
      "\t Using features {4,8,21} accuracy is 80.9%\n",
      "\t Using features {4,9,21} accuracy is 80.5%\n",
      "\t Using features {4,10,21} accuracy is 84.7%\n",
      "\t Using features {4,11,21} accuracy is 82.5%\n",
      "\t Using features {4,12,21} accuracy is 83.2%\n",
      "\t Using features {4,13,21} accuracy is 83.5%\n",
      "\t Using features {4,14,21} accuracy is 83.4%\n",
      "\t Using features {4,15,21} accuracy is 83.9%\n",
      "\t Using features {4,16,21} accuracy is 80.8%\n",
      "\t Using features {4,17,21} accuracy is 81.9%\n",
      "\t Using features {4,18,21} accuracy is 83.4%\n",
      "\t Using features {4,19,21} accuracy is 85.2%\n",
      "\t Using features {4,20,21} accuracy is 84.7%\n",
      "\t Using features {4,21,22} accuracy is 83.0%\n",
      "\t Using features {4,21,23} accuracy is 82.0%\n",
      "\t Using features {4,21,24} accuracy is 84.6%\n",
      "\t Using features {4,21,25} accuracy is 80.2%\n",
      "\t Using features {4,21,26} accuracy is 84.0%\n",
      "\t Using features {4,21,27} accuracy is 82.4%\n",
      "\t Using features {4,21,28} accuracy is 82.3%\n",
      "\t Using features {4,21,29} accuracy is 80.9%\n",
      "\t Using features {4,21,30} accuracy is 80.0%\n",
      "\t Using features {4,21,31} accuracy is 83.1%\n",
      "\t Using features {4,21,32} accuracy is 81.2%\n",
      "\t Using features {4,21,33} accuracy is 80.8%\n",
      "\t Using features {4,21,34} accuracy is 84.6%\n",
      "\t Using features {4,21,35} accuracy is 83.7%\n",
      "\t Using features {4,21,36} accuracy is 82.4%\n",
      "\t Using features {4,21,37} accuracy is 86.7%\n",
      "\t Using features {4,21,38} accuracy is 83.5%\n",
      "\t Using features {4,21,39} accuracy is 78.9%\n",
      "\t Using features {4,21,40} accuracy is 78.1%\n",
      "Feature set  {4,21,37}  was best. accuracy is 86.7% adding feature 37\n",
      "\n",
      "On the  4 th level of the search tree\n",
      "\t Using features {1,4,21,37} accuracy is 80.7%\n",
      "\t Using features {2,4,21,37} accuracy is 78.7%\n",
      "\t Using features {3,4,21,37} accuracy is 81.9%\n",
      "\t Using features {4,5,21,37} accuracy is 81.1%\n",
      "\t Using features {4,6,21,37} accuracy is 83.7%\n",
      "\t Using features {4,7,21,37} accuracy is 82.1%\n",
      "\t Using features {4,8,21,37} accuracy is 78.8%\n",
      "\t Using features {4,9,21,37} accuracy is 78.0%\n",
      "\t Using features {4,10,21,37} accuracy is 80.8%\n",
      "\t Using features {4,11,21,37} accuracy is 77.8%\n",
      "\t Using features {4,12,21,37} accuracy is 78.3%\n",
      "\t Using features {4,13,21,37} accuracy is 77.6%\n",
      "\t Using features {4,14,21,37} accuracy is 80.0%\n",
      "\t Using features {4,15,21,37} accuracy is 79.9%\n",
      "\t Using features {4,16,21,37} accuracy is 79.5%\n",
      "\t Using features {4,17,21,37} accuracy is 79.6%\n",
      "\t Using features {4,18,21,37} accuracy is 82.8%\n",
      "\t Using features {4,19,21,37} accuracy is 82.1%\n",
      "\t Using features {4,20,21,37} accuracy is 84.6%\n",
      "\t Using features {4,21,22,37} accuracy is 83.3%\n",
      "\t Using features {4,21,23,37} accuracy is 80.0%\n",
      "\t Using features {4,21,24,37} accuracy is 83.2%\n",
      "\t Using features {4,21,25,37} accuracy is 81.9%\n",
      "\t Using features {4,21,26,37} accuracy is 82.2%\n",
      "\t Using features {4,21,27,37} accuracy is 76.6%\n",
      "\t Using features {4,21,28,37} accuracy is 79.6%\n",
      "\t Using features {4,21,29,37} accuracy is 75.1%\n",
      "\t Using features {4,21,30,37} accuracy is 79.6%\n",
      "\t Using features {4,21,31,37} accuracy is 79.8%\n",
      "\t Using features {4,21,32,37} accuracy is 78.6%\n",
      "\t Using features {4,21,33,37} accuracy is 81.5%\n",
      "\t Using features {4,21,34,37} accuracy is 85.5%\n",
      "\t Using features {4,21,35,37} accuracy is 81.2%\n",
      "\t Using features {4,21,36,37} accuracy is 80.9%\n",
      "\t Using features {4,21,37,38} accuracy is 81.9%\n",
      "\t Using features {4,21,37,39} accuracy is 76.9%\n",
      "\t Using features {4,21,37,40} accuracy is 79.4%\n",
      "Feature set  {4,21,34,37}  was best. accuracy is 85.5% adding feature 34\n",
      "\n",
      "On the  5 th level of the search tree\n",
      "\t Using features {1,4,21,34,37} accuracy is 78.1%\n",
      "\t Using features {2,4,21,34,37} accuracy is 75.4%\n",
      "\t Using features {3,4,21,34,37} accuracy is 73.3%\n",
      "\t Using features {4,5,21,34,37} accuracy is 75.7%\n",
      "\t Using features {4,6,21,34,37} accuracy is 75.5%\n",
      "\t Using features {4,7,21,34,37} accuracy is 82.3%\n",
      "\t Using features {4,8,21,34,37} accuracy is 73.3%\n",
      "\t Using features {4,9,21,34,37} accuracy is 77.4%\n",
      "\t Using features {4,10,21,34,37} accuracy is 74.2%\n",
      "\t Using features {4,11,21,34,37} accuracy is 74.6%\n",
      "\t Using features {4,12,21,34,37} accuracy is 77.2%\n",
      "\t Using features {4,13,21,34,37} accuracy is 72.9%\n",
      "\t Using features {4,14,21,34,37} accuracy is 76.2%\n",
      "\t Using features {4,15,21,34,37} accuracy is 76.3%\n",
      "\t Using features {4,16,21,34,37} accuracy is 79.6%\n",
      "\t Using features {4,17,21,34,37} accuracy is 78.5%\n",
      "\t Using features {4,18,21,34,37} accuracy is 77.6%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Using features {4,19,21,34,37} accuracy is 78.3%\n",
      "\t Using features {4,20,21,34,37} accuracy is 79.1%\n",
      "\t Using features {4,21,22,34,37} accuracy is 73.8%\n",
      "\t Using features {4,21,23,34,37} accuracy is 77.9%\n",
      "\t Using features {4,21,24,34,37} accuracy is 79.5%\n",
      "\t Using features {4,21,25,34,37} accuracy is 80.3%\n",
      "\t Using features {4,21,26,34,37} accuracy is 80.1%\n",
      "\t Using features {4,21,27,34,37} accuracy is 74.0%\n",
      "\t Using features {4,21,28,34,37} accuracy is 77.0%\n",
      "\t Using features {4,21,29,34,37} accuracy is 73.2%\n",
      "\t Using features {4,21,30,34,37} accuracy is 70.8%\n",
      "\t Using features {4,21,31,34,37} accuracy is 73.7%\n",
      "\t Using features {4,21,32,34,37} accuracy is 78.4%\n",
      "\t Using features {4,21,33,34,37} accuracy is 74.5%\n",
      "\t Using features {4,21,34,35,37} accuracy is 72.8%\n",
      "\t Using features {4,21,34,36,37} accuracy is 74.0%\n",
      "\t Using features {4,21,34,37,38} accuracy is 79.6%\n",
      "\t Using features {4,21,34,37,39} accuracy is 74.0%\n",
      "\t Using features {4,21,34,37,40} accuracy is 77.7%\n",
      "Feature set  {4,7,21,34,37}  was best. accuracy is 82.3% adding feature 7\n",
      "\n",
      "On the  6 th level of the search tree\n",
      "\t Using features {1,4,7,21,34,37} accuracy is 76.9%\n",
      "\t Using features {2,4,7,21,34,37} accuracy is 73.2%\n",
      "\t Using features {3,4,7,21,34,37} accuracy is 72.2%\n",
      "\t Using features {4,5,7,21,34,37} accuracy is 75.6%\n",
      "\t Using features {4,6,7,21,34,37} accuracy is 77.1%\n",
      "\t Using features {4,7,8,21,34,37} accuracy is 74.5%\n",
      "\t Using features {4,7,9,21,34,37} accuracy is 77.5%\n",
      "\t Using features {4,7,10,21,34,37} accuracy is 72.7%\n",
      "\t Using features {4,7,11,21,34,37} accuracy is 76.2%\n",
      "\t Using features {4,7,12,21,34,37} accuracy is 73.9%\n",
      "\t Using features {4,7,13,21,34,37} accuracy is 74.5%\n",
      "\t Using features {4,7,14,21,34,37} accuracy is 75.3%\n",
      "\t Using features {4,7,15,21,34,37} accuracy is 76.2%\n",
      "\t Using features {4,7,16,21,34,37} accuracy is 78.8%\n",
      "\t Using features {4,7,17,21,34,37} accuracy is 77.5%\n",
      "\t Using features {4,7,18,21,34,37} accuracy is 73.2%\n",
      "\t Using features {4,7,19,21,34,37} accuracy is 78.0%\n",
      "\t Using features {4,7,20,21,34,37} accuracy is 81.4%\n",
      "\t Using features {4,7,21,22,34,37} accuracy is 76.9%\n",
      "\t Using features {4,7,21,23,34,37} accuracy is 80.7%\n",
      "\t Using features {4,7,21,24,34,37} accuracy is 77.2%\n",
      "\t Using features {4,7,21,25,34,37} accuracy is 78.8%\n",
      "\t Using features {4,7,21,26,34,37} accuracy is 75.1%\n",
      "\t Using features {4,7,21,27,34,37} accuracy is 74.4%\n"
     ]
    }
   ],
   "source": [
    "# driver function\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    small_dataset_path = 'CS205_SP_2022_SMALLtestdata__35.txt'\n",
    "    large_dataset_path = 'CS205_SP_2022_Largetestdata__62.txt'\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        input_case = input('Press 11 to run Forward Selection with small dataset\\n' + \\\n",
    "                          'Press 12 to run Forward Selection with large dataset\\n' + \\\n",
    "                          'Press 21 to run Backward Elimination with small dataset\\n' + \\\n",
    "                          'Press 22 to run Backward Elimination with large dataset\\n' + \\\n",
    "                          'Press any other key to exit\\n').strip()\n",
    "        \n",
    "        if input_case == '11':\n",
    "            print(\"Forward Selection selected with small dataset\")\n",
    "            instances, instance_count, feature_count = read_dataset(small_dataset_path)\n",
    "            \n",
    "            start_experiment(instances, instance_count, feature_count, FORWARD_SELECTION)\n",
    "            \n",
    "        elif input_case == '12':\n",
    "            print(\"Forward Selection selected with large dataset\")\n",
    "            instances, instance_count, feature_count = read_dataset(large_dataset_path)\n",
    "            \n",
    "            start_experiment(instances, instance_count, feature_count, FORWARD_SELECTION)\n",
    "            \n",
    "        elif input_case == '21':\n",
    "            print('Backward Elimination selected with small dataset')\n",
    "            instances, instance_count, feature_count = read_dataset(small_dataset_path)\n",
    "            \n",
    "            start_experiment(instances, instance_count, feature_count, BACKWARD_ELIMINATION)\n",
    "            \n",
    "        elif input_case == '22':\n",
    "            print('Backward Elimination selected with large dataset')\n",
    "            \n",
    "            instances, instance_count, feature_count = read_dataset(large_dataset_path)\n",
    "            \n",
    "            start_experiment(instances, instance_count, feature_count, BACKWARD_ELIMINATION)\n",
    "        else:\n",
    "            print('Exit. Thank you')\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69213f3b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
