{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ee0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e91f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORWARD_SELECTION, BACKWARD_ELIMINATION = 'forward_selection', 'backward_elimination'\n",
    "K_FOLD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4410796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_path):\n",
    "\n",
    "    data = pd.read_csv(dataset_path, delim_whitespace=True, header = None)\n",
    "    instance_count, column_count = data.shape   \n",
    "    feature_count = column_count - 1\n",
    "    instances = data.values.tolist()\n",
    "    \n",
    "    return instances, instance_count, feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05955524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_euclidean_distance(instance, compare_instance, features):\n",
    "    \n",
    "    squares = 0\n",
    "    for feature in features:\n",
    "        \n",
    "        diff = instance[feature] - compare_instance[feature]\n",
    "        squares += diff ** 2\n",
    "    \n",
    "    return math.sqrt(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4d980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbor(dataset, feature_set, instance_count):\n",
    "    \n",
    "    correct_prediction = 0\n",
    "    for instance_idx in range(instance_count):\n",
    "        \n",
    "        instance = dataset[instance_idx]\n",
    "        target = instance[0]\n",
    "        features = feature_set \n",
    "        \n",
    "        nearest_neighbor_distance = math.inf\n",
    "        nearest_neighbor_predict = -1\n",
    "        \n",
    "        for compare_idx in range(instance_count):\n",
    "            \n",
    "            if compare_idx != instance_idx:\n",
    "                \n",
    "                compare_instance = dataset[compare_idx]\n",
    "                compare_target = compare_instance[0]\n",
    "                distance = find_euclidean_distance(instance,\n",
    "                                                  compare_instance,\n",
    "                                                  features)\n",
    "                \n",
    "                if distance < nearest_neighbor_distance:\n",
    "                        nearest_neighbor_distance = distance\n",
    "                        nearest_neighbor_predict = compare_target\n",
    "         \n",
    "        if nearest_neighbor_predict == target:\n",
    "            correct_prediction += 1\n",
    "        \n",
    "    return correct_prediction / instance_count\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad956c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_cross_validation(instances, instance_count, feature_set):\n",
    "    \n",
    "    \n",
    "    fold_size = instance_count//K_FOLD\n",
    "    accuracy_list = []\n",
    "    for k_fold_itr in range(1, K_FOLD):\n",
    "        \n",
    "        ## dataset\n",
    "        remove_start = (k_fold_itr - 1) * fold_size\n",
    "        remove_end = remove_start + fold_size\n",
    "        \n",
    "        dataset = instances[0:remove_start] + instances[remove_end: instance_count]\n",
    "        \n",
    "        accuracy = find_nearest_neighbor(dataset, feature_set, fold_size)\n",
    "        accuracy_list.append(accuracy)\n",
    "    \n",
    "    return sum(accuracy_list)/K_FOLD\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f474de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_experiment(instances, instance_count, feature_count, search_type = FORWARD_SELECTION):\n",
    "    \n",
    "    print(search_type)\n",
    "    \n",
    "    feature_set = list(range(1, feature_count + 1))\n",
    "    accuracy = leave_one_out_cross_validation(\\\n",
    "                    instances, instance_count, feature_set)\n",
    "    print('Running nearest neighbor with all', feature_count, 'features, using leave-one-out evaluation',\n",
    "         'with accuracy', '{:0.1f}%'.format(accuracy * 100))\n",
    "    \n",
    "    current_feature_set = []\n",
    "    \n",
    "    print()\n",
    "    print('Beginning Search ')\n",
    "    best_accuracy_feature_set = feature_set\n",
    "    best_accuracy = accuracy\n",
    "    for level in range(1, feature_count - 1):\n",
    "        \n",
    "        print('On the ', str(level), 'th level of the search tree')\n",
    "        level_wise_best_accuracy_feature_set = None\n",
    "        level_wise_best_accuracy_feature = None\n",
    "        level_wise_best_accuracy = 0\n",
    "        \n",
    "        for feature in range(1, feature_count - 1):\n",
    "            \n",
    "            if feature not in current_feature_set:\n",
    "                \n",
    "                feature_set = current_feature_set + [feature]\n",
    "                accuracy = leave_one_out_cross_validation(\\\n",
    "                                instances, instance_count, \\\n",
    "                                feature_set)\n",
    "                \n",
    "                feature_set_string = ','.join(str(f) for f in feature_set)\n",
    "                print('\\t Using features',  feature_set_string, 'accuracy is', '{:0.1f}%'.format(accuracy * 100) )\n",
    "                \n",
    "                if accuracy > level_wise_best_accuracy:\n",
    "                    level_wise_best_accuracy = accuracy\n",
    "                    level_wise_best_accuracy_feature = feature\n",
    "                    level_wise_best_accuracy_feature_set = feature_set\n",
    "                    level_wise_best_accuracy_feature_set.sort()\n",
    "                    \n",
    "        current_feature_set.append(level_wise_best_accuracy_feature)\n",
    "        level_wise_best_feature_set_string = ','.join(str(f) for f in level_wise_best_accuracy_feature_set)\n",
    "        print('Feature set ', level_wise_best_feature_set_string, \\\n",
    "              ' was best. accuracy is', '{:0.1f}%'.format(level_wise_best_accuracy*100) )\n",
    "        print()\n",
    "        \n",
    "        if level_wise_best_accuracy > best_accuracy:\n",
    "            best_accuracy = level_wise_best_accuracy\n",
    "            best_accuracy_feature_set = level_wise_best_accuracy_feature_set\n",
    "    \n",
    "    best_accuracy_feature_set_string = ','.join(str(f) for f in best_accuracy_feature_set)\n",
    "    print('Finished search !!', 'The best feature subset is', best_accuracy_feature_set_string, \\\n",
    "             'which has an accuracy of', '{:0.1f}%'.format(best_accuracy*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4dd1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 11 to run Forward Selection with small dataset\n",
      "Press 12 to run Forward Selection with large dataset\n",
      "Press 21 to run Backward Elimination with small dataset\n",
      "Press 22 to run Backward Elimination with large dataset\n",
      "Press any other key to exit\n",
      "11\n",
      "Forward Selection selected with small dataset\n",
      "forward_selection\n",
      "Running nearest neighbor with all 10 features, using leave-one-out evaluation with accuracy 65.33%\n",
      "\n",
      "Beginning Search \n",
      "On the  1 th level of the search tree\n",
      "\t Using features 1 accuracy is 71.33%\n",
      "\t Using features 2 accuracy is 70.33%\n",
      "\t Using features 3 accuracy is 71.67%\n",
      "\t Using features 4 accuracy is 68.00%\n",
      "\t Using features 5 accuracy is 65.00%\n",
      "\t Using features 6 accuracy is 65.00%\n",
      "\t Using features 7 accuracy is 65.00%\n",
      "\t Using features 8 accuracy is 75.00%\n",
      "Feature set  8  was best. accuracy is 75.0%\n",
      "\n",
      "On the  2 th level of the search tree\n",
      "\t Using features 8,1 accuracy is 75.00%\n",
      "\t Using features 8,2 accuracy is 80.67%\n",
      "\t Using features 8,3 accuracy is 78.67%\n",
      "\t Using features 8,4 accuracy is 76.67%\n",
      "\t Using features 8,5 accuracy is 73.33%\n",
      "\t Using features 8,6 accuracy is 77.33%\n",
      "\t Using features 8,7 accuracy is 86.00%\n",
      "Feature set  7,8  was best. accuracy is 86.0%\n",
      "\n",
      "On the  3 th level of the search tree\n",
      "\t Using features 8,7,1 accuracy is 68.00%\n",
      "\t Using features 8,7,2 accuracy is 72.00%\n",
      "\t Using features 8,7,3 accuracy is 70.00%\n",
      "\t Using features 8,7,4 accuracy is 76.67%\n",
      "\t Using features 8,7,5 accuracy is 77.67%\n",
      "\t Using features 8,7,6 accuracy is 79.33%\n",
      "Feature set  6,7,8  was best. accuracy is 79.3%\n",
      "\n",
      "On the  4 th level of the search tree\n",
      "\t Using features 8,7,6,1 accuracy is 69.33%\n",
      "\t Using features 8,7,6,2 accuracy is 73.33%\n",
      "\t Using features 8,7,6,3 accuracy is 72.00%\n",
      "\t Using features 8,7,6,4 accuracy is 81.67%\n",
      "\t Using features 8,7,6,5 accuracy is 70.67%\n",
      "Feature set  4,6,7,8  was best. accuracy is 81.7%\n",
      "\n",
      "On the  5 th level of the search tree\n",
      "\t Using features 8,7,6,4,1 accuracy is 61.00%\n",
      "\t Using features 8,7,6,4,2 accuracy is 70.33%\n",
      "\t Using features 8,7,6,4,3 accuracy is 68.67%\n",
      "\t Using features 8,7,6,4,5 accuracy is 73.00%\n",
      "Feature set  4,5,6,7,8  was best. accuracy is 73.0%\n",
      "\n",
      "On the  6 th level of the search tree\n",
      "\t Using features 8,7,6,4,5,1 accuracy is 61.00%\n",
      "\t Using features 8,7,6,4,5,2 accuracy is 65.00%\n",
      "\t Using features 8,7,6,4,5,3 accuracy is 74.33%\n",
      "Feature set  3,4,5,6,7,8  was best. accuracy is 74.3%\n",
      "\n",
      "On the  7 th level of the search tree\n",
      "\t Using features 8,7,6,4,5,3,1 accuracy is 58.33%\n",
      "\t Using features 8,7,6,4,5,3,2 accuracy is 71.00%\n",
      "Feature set  2,3,4,5,6,7,8  was best. accuracy is 71.0%\n",
      "\n",
      "On the  8 th level of the search tree\n",
      "\t Using features 8,7,6,4,5,3,2,1 accuracy is 60.33%\n",
      "Feature set  1,2,3,4,5,6,7,8  was best. accuracy is 60.3%\n",
      "\n",
      "Finished search !! The best feature subset is 7,8 which has an accuracy of 86.0%\n"
     ]
    }
   ],
   "source": [
    "# driver function\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    small_dataset_path = 'CS205_SP_2022_SMALLtestdata__35.txt'\n",
    "    large_dataset_path = 'CS205_SP_2022_Largetestdata__62.txt'\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        input_case = input('Press 11 to run Forward Selection with small dataset\\n' + \\\n",
    "                          'Press 12 to run Forward Selection with large dataset\\n' + \\\n",
    "                          'Press 21 to run Backward Elimination with small dataset\\n' + \\\n",
    "                          'Press 22 to run Backward Elimination with large dataset\\n' + \\\n",
    "                          'Press any other key to exit\\n').strip()\n",
    "        \n",
    "        if input_case == '11':\n",
    "            print(\"Forward Selection selected with small dataset\")\n",
    "            instances, instance_count, feature_count = read_dataset(small_dataset_path)\n",
    "            \n",
    "            start_experiment(instances, instance_count, feature_count, FORWARD_SELECTION)\n",
    "            \n",
    "        elif input_case == '12':\n",
    "            print(\"Forward Selection selected with large dataset\")\n",
    "            instances, instance_count, feature_count = read_dataset(large_dataset_path)\n",
    "            \n",
    "            start_experiment(instances, instance_count, feature_count, FORWARD_SELECTION)\n",
    "            \n",
    "        elif input_case == '21':\n",
    "            print('Backward Elimination selected with small dataset')\n",
    "            instances, instance_count, feature_count = read_dataset(small_dataset_path)\n",
    "            \n",
    "            start_experiment(instances, instance_count, feature_count, BACKWARD_ELIMINATION)\n",
    "            \n",
    "        elif input_case == '22':\n",
    "            print('Backward Elimination selected with large dataset')\n",
    "            \n",
    "            instances, instance_count, feature_count = read_dataset(large_dataset_path)\n",
    "            \n",
    "            start_experiment(instances, instance_count, feature_count, BACKWARD_ELIMINATION)\n",
    "        else:\n",
    "            print('Exit. Thank you')\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffff09c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
