{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ee0d1d",
   "metadata": {
    "id": "17ee0d1d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f58b6004",
   "metadata": {
    "id": "f58b6004"
   },
   "outputs": [],
   "source": [
    "# feature selection type variables\n",
    "FORWARD_SELECTION, BACKWARD_ELIMINATION = 'forward_selection', 'backward_elimination'\n",
    "\n",
    "# cache to reduce the computational cost during measurement of euclidean distance\n",
    "cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c78b54c7",
   "metadata": {
    "id": "c78b54c7"
   },
   "outputs": [],
   "source": [
    "# given a file path of the dataset, method reads dataset\n",
    "# and returns all the instances with their labels\n",
    "# and feature count per instance\n",
    "def read_dataset(dataset_path):\n",
    "\n",
    "    data = pd.read_csv(dataset_path, delim_whitespace=True, header = None)\n",
    "    instance_count, column_count = data.shape   \n",
    "    feature_count = column_count - 1\n",
    "    instances = data.values.tolist()\n",
    "    \n",
    "    return instances, instance_count, feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324bf4ea",
   "metadata": {
    "id": "324bf4ea"
   },
   "outputs": [],
   "source": [
    "# given two instances of the dataset, and a list of features to be considered\n",
    "# method find the euclidean distance based on the features given\n",
    "# the method uses a global cache to reduce the computational cost incurred\n",
    "# to find the distance, whenever it finds two features, that are already stored\n",
    "# in the map with its squared difference, the method gets the value from the map\n",
    "# otherwise, it calculates the value and stores in the map for further usage\n",
    "def find_euclidean_distance(instance, compare_instance, features):\n",
    "    \n",
    "    squares = 0\n",
    "    # iterates over the given features\n",
    "    for feature in features:\n",
    "        \n",
    "        x = instance[feature]\n",
    "        y = compare_instance[feature]\n",
    "        val = 0\n",
    "        \n",
    "        # searching if already the calculated value is in the cache\n",
    "        if (x,y) in cache:\n",
    "            val = cache[(x, y)]\n",
    "        elif (y,x) in cache:\n",
    "            val = cache[(y, x)]\n",
    "        else:\n",
    "            diff = x - y\n",
    "            val = diff ** 2\n",
    "            \n",
    "            cache[(x, y)] = val\n",
    "            \n",
    "        squares += val\n",
    "    \n",
    "    return math.sqrt(squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f997e96",
   "metadata": {
    "id": "6f997e96"
   },
   "outputs": [],
   "source": [
    "# given the dataset and feature set to be considered\n",
    "# method predicts the label of the instance and compares the predicted one with\n",
    "# the given label using nearest neighbor classifier where k = 1\n",
    "# method returns the ratio of count of correctly predicted instances and\n",
    "# total instances\n",
    "def find_nearest_neighbor(dataset, feature_set, instance_count):\n",
    "    \n",
    "    correct_prediction = 0\n",
    "    # iterating over each of the instance\n",
    "    for instance_idx in range(instance_count):\n",
    "        \n",
    "        # extracts the current instance\n",
    "        instance = dataset[instance_idx]\n",
    "        # extracts the label of the current instance\n",
    "        target = instance[0]\n",
    "        # the set of features to be considered\n",
    "        features = feature_set \n",
    "        \n",
    "        nearest_neighbor_distance = math.inf\n",
    "        nearest_neighbor_predict = -1\n",
    "        \n",
    "        # iterates over each of the other instances in the dataset\n",
    "        # to find which instance is more close in respect of euclidean \n",
    "        # distance\n",
    "        for compare_idx in range(instance_count):\n",
    "            \n",
    "            if compare_idx != instance_idx:\n",
    "                \n",
    "                compare_instance = dataset[compare_idx]\n",
    "                compare_target = compare_instance[0]\n",
    "                distance = find_euclidean_distance(instance,\n",
    "                                                  compare_instance,\n",
    "                                                  features)\n",
    "                \n",
    "                if distance < nearest_neighbor_distance:\n",
    "                        nearest_neighbor_distance = distance\n",
    "                        nearest_neighbor_predict = compare_target\n",
    "        \n",
    "        # checking whether the predicted label matches the target label\n",
    "        if nearest_neighbor_predict == target:\n",
    "            correct_prediction += 1\n",
    "\n",
    "    # returns the ratio of the count of correctly predicted instance and \n",
    "    # total instances    \n",
    "    return correct_prediction / instance_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f352d693",
   "metadata": {
    "id": "f352d693"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plots a graph to show how accuracy gets affected by feature counts\n",
    "def plot_graph(accuracy_map, search_type, dataset_size):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for key in sorted(accuracy_map):\n",
    "        x.append(key)\n",
    "        y.append(accuracy_map[key])\n",
    "        \n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Feature Count')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('' + search_type.upper() + ' Dataset ' + dataset_size)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ddfb41f",
   "metadata": {
    "id": "1ddfb41f"
   },
   "outputs": [],
   "source": [
    "# given the instances and feature set to be considered,\n",
    "# method iteratively leaves one instance, runs nearest neighbor classifier on\n",
    "# the remaining instances, and finds the accuracy, that is how, the number of \n",
    "# validation set will be equal to the number of instance count\n",
    "# returns the average of the accuracy over all the validation sets\n",
    "def leave_one_out_cross_validation(instances, instance_count, feature_set):\n",
    "    \n",
    "    accuracy_list = []\n",
    "    # iterates over each of the instances\n",
    "    for k_fold_itr in range(0, instance_count):\n",
    "        \n",
    "        # prepares a dataset removing k_fold_itr th instance\n",
    "        dataset = instances[ :k_fold_itr] + instances[k_fold_itr + 1: ]\n",
    "\n",
    "        # runs nearest neighbor classifier to finds accuracy \n",
    "        accuracy = find_nearest_neighbor(dataset, feature_set, \\\n",
    "                                         instance_count - 1)\n",
    "        \n",
    "        # appendds the accuracy in a list\n",
    "        accuracy_list.append(accuracy)\n",
    "    \n",
    "    # returns the average accuracy found\n",
    "    return sum(accuracy_list)/instance_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74381ba8",
   "metadata": {
    "id": "74381ba8"
   },
   "outputs": [],
   "source": [
    "# given the type of feature selection type along with all the instances\n",
    "# iterates over different sets of features (based on the type of feature \n",
    "# selection given)\n",
    "# for each different set of feature, finds leave-one-out validation accuracy\n",
    "# using nearest neighbor classifier (k = 1)\n",
    "# prints the best accuracy with the best feature set\n",
    "# returns the best accuracy to best feature set per level to plot graph \n",
    "def start_experiment(instances, instance_count, feature_count, \\\n",
    "                     search_type = FORWARD_SELECTION):\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(search_type.upper())\n",
    "    accuracy_map = {}\n",
    "    \n",
    "    all_feature_set = list(range(1, feature_count + 1))\n",
    "    accuracy = leave_one_out_cross_validation(\\\n",
    "                    instances, instance_count, all_feature_set)\n",
    "    print('Running nearest neighbor with all', feature_count, \\\n",
    "          'features, using leave-one-out evaluation',\n",
    "         'with accuracy', '{:0.1f}%'.format(accuracy * 100))\n",
    "    accuracy_map[len(all_feature_set)] = accuracy\n",
    "    \n",
    "    # starts with an empty feature set for forward selection\n",
    "    # starts with all features for backward elimination\n",
    "    if search_type == FORWARD_SELECTION:\n",
    "        current_feature_set = []\n",
    "    elif search_type == BACKWARD_ELIMINATION:\n",
    "        current_feature_set = all_feature_set\n",
    "    \n",
    "    print()\n",
    "    print('Beginning Search ')\n",
    "    best_accuracy_feature_set = all_feature_set\n",
    "    best_accuracy = accuracy\n",
    "    \n",
    "    # iterating over each of the level\n",
    "    # on each level, either the count of features\n",
    "    # equal to  (level count) (forward selection)\n",
    "    # or (total feature count - level count) (backward elimination)\n",
    "    for level in range(1, feature_count):\n",
    "        \n",
    "        print('On the ', str(level), 'th level of the search tree')\n",
    "        level_wise_best_accuracy_feature_set = None\n",
    "        level_wise_best_accuracy_feature = None\n",
    "        level_wise_best_accuracy = 0\n",
    "        \n",
    "        # iterating over each of the features which can be added\n",
    "        # or removed for feature selection/backward elimination\n",
    "        # respectively\n",
    "        for feature in range(1, feature_count + 1):\n",
    "            \n",
    "            if (feature not in current_feature_set and \\\n",
    "                search_type == FORWARD_SELECTION) or \\\n",
    "                (feature in current_feature_set and \\\n",
    "                 search_type == BACKWARD_ELIMINATION):\n",
    "                \n",
    "                if search_type == FORWARD_SELECTION:\n",
    "                    feature_set = current_feature_set + [feature]\n",
    "                elif search_type == BACKWARD_ELIMINATION:\n",
    "                    feature_set = list(set(current_feature_set) - set([feature]))\n",
    "                \n",
    "                # finding leave one out cross validation accuracy\n",
    "                accuracy = leave_one_out_cross_validation(\\\n",
    "                                instances, instance_count, \\\n",
    "                                feature_set)\n",
    "                \n",
    "                # sorting for displaying results in good manner\n",
    "                feature_set.sort()\n",
    "                feature_set_string = '{' + ','.join(str(f) \\\n",
    "                                                    for f in feature_set) + '}'\n",
    "                print('\\t Using features',  feature_set_string, 'accuracy is', \\\n",
    "                      '{:0.1f}%'.format(accuracy * 100) )\n",
    "                \n",
    "                # checks if current feature set provides the better accuracy\n",
    "                # among the feature sets in the current level\n",
    "                if accuracy > level_wise_best_accuracy:\n",
    "                    level_wise_best_accuracy = accuracy\n",
    "                    level_wise_best_accuracy_feature = feature\n",
    "                    level_wise_best_accuracy_feature_set = feature_set\n",
    "                    \n",
    "        if search_type == FORWARD_SELECTION:\n",
    "            current_feature_set.append(level_wise_best_accuracy_feature)\n",
    "            add_remove_log = 'adding ' + 'feature ' + \\\n",
    "                str(level_wise_best_accuracy_feature)\n",
    "        elif search_type == BACKWARD_ELIMINATION:\n",
    "            current_feature_set = list(set(current_feature_set) - \\\n",
    "                                        set([level_wise_best_accuracy_feature]))\n",
    "            add_remove_log = 'removing ' + 'feature ' + \\\n",
    "                              str(level_wise_best_accuracy_feature)\n",
    "            \n",
    "        \n",
    "        level_wise_best_feature_set_string = '{' + ','.join(str(f) \\\n",
    "                            for f in level_wise_best_accuracy_feature_set) + '}'\n",
    "        print('Feature set ', level_wise_best_feature_set_string, \\\n",
    "              ' was best. accuracy is', '{:0.1f}%'.format(\\\n",
    "                                level_wise_best_accuracy*100), add_remove_log )\n",
    "        \n",
    "        accuracy_map[len(level_wise_best_accuracy_feature_set)] = \\\n",
    "                                level_wise_best_accuracy\n",
    "        print()\n",
    "        \n",
    "        # checks if current level accuracy is best among the so far\n",
    "        # feature sets considered\n",
    "        if level_wise_best_accuracy > best_accuracy:\n",
    "            best_accuracy = level_wise_best_accuracy\n",
    "            best_accuracy_feature_set = level_wise_best_accuracy_feature_set\n",
    "    \n",
    "    # displays the best accuracy calculated with the best feature set\n",
    "    best_accuracy_feature_set_string = '{' + ','.join(str(f) \\\n",
    "                                for f in best_accuracy_feature_set) + '}'\n",
    "    print('Finished search !!', 'The best feature subset is', \\\n",
    "                                best_accuracy_feature_set_string, \\\n",
    "             'which has an accuracy of', '{:0.1f}%'.format(best_accuracy*100) )\n",
    "    \n",
    "    return accuracy_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4dd1f1",
   "metadata": {
    "id": "3b4dd1f1",
    "outputId": "07e9e60d-276d-4023-ab22-bfee0f81be21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 11 to run Forward Selection with small dataset\n",
      "Press 12 to run Forward Selection with large dataset\n",
      "Press 21 to run Backward Elimination with small dataset\n",
      "Press 22 to run Backward Elimination with large dataset\n",
      "Press any other key to exit\n",
      "11\n",
      "Forward Selection selected with small dataset\n",
      "\n",
      "\n",
      "FORWARD_SELECTION\n",
      "Running nearest neighbor with all 10 features, using leave-one-out evaluation with accuracy 72.3%\n",
      "\n",
      "Beginning Search \n",
      "On the  1 th level of the search tree\n",
      "\t Using features {1} accuracy is 67.4%\n",
      "\t Using features {2} accuracy is 65.7%\n",
      "\t Using features {3} accuracy is 69.7%\n",
      "\t Using features {4} accuracy is 66.3%\n",
      "\t Using features {5} accuracy is 71.0%\n",
      "\t Using features {6} accuracy is 73.3%\n",
      "\t Using features {7} accuracy is 76.3%\n",
      "\t Using features {8} accuracy is 90.3%\n",
      "\t Using features {9} accuracy is 69.7%\n",
      "\t Using features {10} accuracy is 68.0%\n",
      "Feature set  {8}  was best. accuracy is 90.3% adding feature 8\n",
      "\n",
      "On the  2 th level of the search tree\n",
      "\t Using features {1,8} accuracy is 88.0%\n",
      "\t Using features {2,8} accuracy is 82.7%\n",
      "\t Using features {3,8} accuracy is 83.0%\n",
      "\t Using features {4,8} accuracy is 81.3%\n",
      "\t Using features {5,8} accuracy is 81.7%\n",
      "\t Using features {6,8} accuracy is 84.7%\n",
      "\t Using features {7,8} accuracy is 96.3%\n",
      "\t Using features {8,9} accuracy is 82.0%\n",
      "\t Using features {8,10} accuracy is 85.0%\n",
      "Feature set  {7,8}  was best. accuracy is 96.3% adding feature 7\n",
      "\n",
      "On the  3 th level of the search tree\n",
      "\t Using features {1,7,8} accuracy is 89.0%\n",
      "\t Using features {2,7,8} accuracy is 89.3%\n",
      "\t Using features {3,7,8} accuracy is 90.0%\n",
      "\t Using features {4,7,8} accuracy is 87.3%\n",
      "\t Using features {5,7,8} accuracy is 91.7%\n",
      "\t Using features {6,7,8} accuracy is 92.0%\n",
      "\t Using features {7,8,9} accuracy is 93.0%\n",
      "\t Using features {7,8,10} accuracy is 94.3%\n",
      "Feature set  {7,8,10}  was best. accuracy is 94.3% adding feature 10\n",
      "\n",
      "On the  4 th level of the search tree\n",
      "\t Using features {1,7,8,10} accuracy is 85.7%\n",
      "\t Using features {2,7,8,10} accuracy is 85.3%\n",
      "\t Using features {3,7,8,10} accuracy is 87.7%\n",
      "\t Using features {4,7,8,10} accuracy is 89.6%\n",
      "\t Using features {5,7,8,10} accuracy is 85.7%\n",
      "\t Using features {6,7,8,10} accuracy is 90.3%\n",
      "\t Using features {7,8,9,10} accuracy is 87.0%\n",
      "Feature set  {6,7,8,10}  was best. accuracy is 90.3% adding feature 6\n",
      "\n",
      "On the  5 th level of the search tree\n",
      "\t Using features {1,6,7,8,10} accuracy is 85.6%\n",
      "\t Using features {2,6,7,8,10} accuracy is 81.3%\n",
      "\t Using features {3,6,7,8,10} accuracy is 83.0%\n",
      "\t Using features {4,6,7,8,10} accuracy is 87.0%\n",
      "\t Using features {5,6,7,8,10} accuracy is 84.3%\n",
      "\t Using features {6,7,8,9,10} accuracy is 83.6%\n",
      "Feature set  {4,6,7,8,10}  was best. accuracy is 87.0% adding feature 4\n",
      "\n",
      "On the  6 th level of the search tree\n",
      "\t Using features {1,4,6,7,8,10} accuracy is 79.7%\n",
      "\t Using features {2,4,6,7,8,10} accuracy is 81.6%\n",
      "\t Using features {3,4,6,7,8,10} accuracy is 85.0%\n",
      "\t Using features {4,5,6,7,8,10} accuracy is 79.3%\n",
      "\t Using features {4,6,7,8,9,10} accuracy is 79.0%\n",
      "Feature set  {3,4,6,7,8,10}  was best. accuracy is 85.0% adding feature 3\n",
      "\n",
      "On the  7 th level of the search tree\n",
      "\t Using features {1,3,4,6,7,8,10} accuracy is 78.0%\n",
      "\t Using features {2,3,4,6,7,8,10} accuracy is 78.3%\n",
      "\t Using features {3,4,5,6,7,8,10} accuracy is 80.7%\n",
      "\t Using features {3,4,6,7,8,9,10} accuracy is 74.0%\n",
      "Feature set  {3,4,5,6,7,8,10}  was best. accuracy is 80.7% adding feature 5\n",
      "\n",
      "On the  8 th level of the search tree\n",
      "\t Using features {1,3,4,5,6,7,8,10} accuracy is 79.6%\n",
      "\t Using features {2,3,4,5,6,7,8,10} accuracy is 77.7%\n",
      "\t Using features {3,4,5,6,7,8,9,10} accuracy is 78.0%\n",
      "Feature set  {1,3,4,5,6,7,8,10}  was best. accuracy is 79.6% adding feature 1\n",
      "\n",
      "On the  9 th level of the search tree\n",
      "\t Using features {1,2,3,4,5,6,7,8,10} accuracy is 76.3%\n",
      "\t Using features {1,3,4,5,6,7,8,9,10} accuracy is 77.0%\n",
      "Feature set  {1,3,4,5,6,7,8,9,10}  was best. accuracy is 77.0% adding feature 9\n",
      "\n",
      "Finished search !! The best feature subset is {7,8} which has an accuracy of 96.3%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time  11637.9 seconds\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# driver function\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "#     small_dataset_path = 'CS205_CalibrationData__1.txt'\n",
    "    \n",
    "    small_dataset_path = 'CS205_SP_2022_SMALLtestdata__35.txt'\n",
    "    large_dataset_path = 'CS205_SP_2022_Largetestdata__62.txt'\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        input_case = input('Press 11 to run Forward Selection with small dataset\\n' + \\\n",
    "                          'Press 12 to run Forward Selection with large dataset\\n' + \\\n",
    "                          'Press 21 to run Backward Elimination with small dataset\\n' + \\\n",
    "                          'Press 22 to run Backward Elimination with large dataset\\n' + \\\n",
    "                          'Press any other key to exit\\n').strip()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if input_case == '11':\n",
    "            print(\"Forward Selection selected with small dataset\")\n",
    "            instances, instance_count, feature_count = read_dataset(small_dataset_path)\n",
    "            \n",
    "            accuracy_map = start_experiment(instances, instance_count, \\\n",
    "                                            feature_count, FORWARD_SELECTION)\n",
    "            plot_graph(accuracy_map, FORWARD_SELECTION, 'small')\n",
    "                \n",
    "        elif input_case == '12':\n",
    "            print(\"Forward Selection selected with large dataset\")\n",
    "            instances, instance_count, feature_count = read_dataset(large_dataset_path)\n",
    "            \n",
    "            accuracy_map = start_experiment(instances, instance_count, \\\n",
    "                                            feature_count, FORWARD_SELECTION)\n",
    "            plot_graph(accuracy_map, FORWARD_SELECTION, 'large')\n",
    "            \n",
    "            \n",
    "        elif input_case == '21':\n",
    "            print('Backward Elimination selected with small dataset')\n",
    "            instances, instance_count, feature_count = read_dataset(small_dataset_path)\n",
    "            \n",
    "            accuracy_map = start_experiment(instances, instance_count, \\\n",
    "                                            feature_count, BACKWARD_ELIMINATION)\n",
    "            plot_graph(accuracy_map, BACKWARD_ELIMINATION, 'small')\n",
    "            \n",
    "            \n",
    "        elif input_case == '22':\n",
    "            print('Backward Elimination selected with large dataset')\n",
    "            \n",
    "            instances, instance_count, feature_count = read_dataset(large_dataset_path)\n",
    "            \n",
    "            accuracy_map = start_experiment(instances, instance_count, \\\n",
    "                                            feature_count, BACKWARD_ELIMINATION)\n",
    "            plot_graph(accuracy_map, BACKWARD_ELIMINATION, 'large')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print('Exit. Thank you')\n",
    "            break\n",
    "        \n",
    "        end_time = time.time()\n",
    "        execution_time_in_seconds = end_time - start_time\n",
    "        print('Execution time ', '{:0.1f} seconds'.format(execution_time_in_seconds))\n",
    "        \n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380aed94",
   "metadata": {
    "id": "380aed94"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Feature_Selection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
